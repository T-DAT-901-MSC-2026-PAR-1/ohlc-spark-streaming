services:
  spark-submit:
    build:
      context: ../../
      dockerfile: docker/dev/Dockerfile
    container_name: spark-submit-runner
    # mount repository into the container so spark can run the application
    working_dir: /opt/app
    volumes:
      # mount repository root (compose file is in docker/dev/) into /opt/app
      - ../../:/opt/app:ro
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS}
      - KAFKA_SUBSCRIBE_TOPICS=${KAFKA_SUBSCRIBE_TOPICS}
      - KAFKA_OUTPUT_PREFIX={KAFKA_OUTPUT_PREFIX}
      - CHECKPOINT_LOCATION=${CHECKPOINT_LOCATION}
      - WINDOW_DURATION=${WINDOW_DURATION}
      - WATERMARK_DELAY=${WATERMARK_DELAY}
      - SPARK_APP_NAME=${SPARK_APP_NAME}
      - SPARK_MASTER_URL=${SPARK_MASTER_URL}
    # Use the custom image entrypoint to control spark-submit invocation
    # For structured streaming the driver runs indefinitely; keep the container running
    restart: unless-stopped
    networks:
      - spark_spark
      - kafka_kafka
    ports:
      - 4040:4040

networks:
  # Use the external Spark network where the spark-master service is defined
  spark_spark:
    external: true
  kafka_kafka:
    external: true

